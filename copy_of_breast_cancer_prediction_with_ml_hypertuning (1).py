# -*- coding: utf-8 -*-
"""Copy of Breast Cancer Prediction with ML hypertuning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FSYtHHZbp_1plcHW5t8CtVs9bhiUiRIg
"""

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES
# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

import os
import sys
from tempfile import NamedTemporaryFile
from urllib.request import urlopen
from urllib.parse import unquote, urlparse
from urllib.error import HTTPError
from zipfile import ZipFile
import tarfile
import shutil

CHUNK_SIZE = 40960
DATA_SOURCE_MAPPING = 'breast-cancer-prediction-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F56485%2F108594%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240726%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240726T164754Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db4a59118d4b42b0489aee8371ef83425617bc84263efe6001c836da5b0d9b727b894da7cbd8b8082f23d58122431f3f21c267ed756fd932ae5797989fbed75609fc8a21ac764785cde7bc41055e747cc56e97e7e6046be0b5af103ab0aabf40c0439e9e6108b5901b74f356f2ef1bdac1ba1a931d17e6e6875c824efa5e4ab90c0b541ec459327046f0a556dd2ec3c3c4334b8820c79c9c5e1bd7c63b87e0f284c485bdab3ef15e3412f065198a1e982bc72f36ace4ff8222fdf1b96d63872655e8f251e3d5a4105cc970dcd277122c0dffcfbe9b839a80a440ec70fc97de6964e197270f5724fd608d3f83757ef491e5694e74fea6d32d8f929a2cc8e6cf4b7'

KAGGLE_INPUT_PATH='/kaggle/input'
KAGGLE_WORKING_PATH='/kaggle/working'
KAGGLE_SYMLINK='kaggle'

!umount /kaggle/input/ 2> /dev/null
shutil.rmtree('/kaggle/input', ignore_errors=True)
os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)
os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)

try:
  os.symlink(KAGGLE_INPUT_PATH, os.path.join("..", 'input'), target_is_directory=True)
except FileExistsError:
  pass
try:
  os.symlink(KAGGLE_WORKING_PATH, os.path.join("..", 'working'), target_is_directory=True)
except FileExistsError:
  pass

for data_source_mapping in DATA_SOURCE_MAPPING.split(','):
    directory, download_url_encoded = data_source_mapping.split(':')
    download_url = unquote(download_url_encoded)
    filename = urlparse(download_url).path
    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)
    try:
        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:
            total_length = fileres.headers['content-length']
            print(f'Downloading {directory}, {total_length} bytes compressed')
            dl = 0
            data = fileres.read(CHUNK_SIZE)
            while len(data) > 0:
                dl += len(data)
                tfile.write(data)
                done = int(50 * dl / int(total_length))
                sys.stdout.write(f"\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded")
                sys.stdout.flush()
                data = fileres.read(CHUNK_SIZE)
            if filename.endswith('.zip'):
              with ZipFile(tfile) as zfile:
                zfile.extractall(destination_path)
            else:
              with tarfile.open(tfile.name) as tarfile:
                tarfile.extractall(destination_path)
            print(f'\nDownloaded and uncompressed: {directory}')
    except HTTPError as e:
        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')
        continue
    except OSError as e:
        print(f'Failed to load {download_url} to path {destination_path}')
        continue

print('Data source import complete.')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GridSearchCV

"""
>**Introduction:
We have the breast cancer data set to predict if a cancer is malignant or not. In this dataset, I stated with some exploratory data analysis. Then I used classification models, Logistic Regression, KNN, Random Forest and Decision Tree to classify the data. I also hypertuned the model to get better results.
******"""

csv_file='../input/breast-cancer-prediction-dataset/Breast_cancer_data.csv'
data_df=pd.read_csv(csv_file)
data_df

data_df.shape

data_df["diagnosis"].value_counts()

data_df.isnull().sum()

data_df.dtypes

plt.hist(data_df['mean_area'])

plt.hist(data_df['mean_radius'])

plt.hist(data_df['mean_texture'])

plt.hist(data_df['mean_perimeter'])

plt.hist(data_df['mean_smoothness'])

sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_radius'],hue=data_df['diagnosis'])

sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_smoothness'],hue=data_df['diagnosis'])

sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_perimeter'],hue=data_df['diagnosis'])

sns.scatterplot(x=data_df['mean_area'],y=data_df['mean_texture'],hue=data_df['diagnosis'])

sns.scatterplot(x=data_df['mean_smoothness'],y=data_df['mean_texture'],hue=data_df['diagnosis'])

data_df.corr()

"""Mean Radius, Mean Perimeter and Mean Area are highly correlated."""

sns.pairplot(data_df,hue='diagnosis')

x = data_df.drop('diagnosis', axis=1) # Set axis explicitly for older pandas versions
x

y= data_df['diagnosis']

from sklearn.model_selection import train_test_split

X_train,X_test,Y_train,Y_test = train_test_split(x,y,test_size=0.2,random_state=10)

X_train.values

X_test.values

Y_test

Y_train

"""##Random Forest"""

from sklearn.ensemble import RandomForestClassifier

forest_model_test = RandomForestClassifier(max_depth=40,random_state=42)
forest_model_test.fit(X_train,Y_train)
Y_random_model_test =forest_model_test.predict(X_test)

forest_model_best= RandomForestClassifier(n_estimators=700,max_depth=10)

forest_model_best.fit(X_train,Y_train)

Y_random_model =forest_model_best.predict(X_test)

forest_confusion = confusion_matrix(Y_random_model,Y_test)

forest_confusion

forest_model_best.score(X_test,Y_test)

precision_score(Y_test,Y_random_model)

recall_score(Y_test,Y_random_model)

False_negetive_rate_Forest = forest_confusion[1][0]/(forest_confusion[1][0]+forest_confusion[1][1])

False_negetive_rate_Forest*100

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import plot_tree

# Load the breast cancer dataset
data = load_breast_cancer()
X = data.data
Y = data.target

# Initialize and train a RandomForestClassifier
rf = RandomForestClassifier() # Create a RandomForestClassifier object
rf.fit(X, Y) # Train the model

# Feature importance plot
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure()
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[indices], align="center")
plt.xticks(range(X.shape[1]), data.feature_names[indices], rotation=90)
plt.show()

# Plot a single tree
plt.figure(figsize=(20,10))
plot_tree(rf.estimators_[0], feature_names=data.feature_names, class_names=data.target_names, filled=True)
plt.show()

"""# **K** Nearest Neighbour"""

from sklearn.neighbors import KNeighborsClassifier

KNN_model =   KNeighborsClassifier(n_neighbors=10)
KNN_model.fit(X_train_scale,Y_train)

Y_KNN =KNN_model.predict(X_test_scale)

KNN_Confusion = confusion_matrix(Y_KNN,Y_test)

KNN_Confusion

accuracy_score(Y_test,Y_KNN)

recall_score(Y_test,Y_KNN)

precision_score(Y_test,Y_KNN)

"""# **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier

Tree_model_test = DecisionTreeClassifier(max_depth = 10)
Tree_model_test.fit(X_train,Y_train)

Y_tree_test = Tree_model_test.predict(X_test)

confusion_matrix(Y_test,Y_tree_test)

accuracy_score(Y_test,Y_tree_test) # Use the correct variable name Y_tree_test

precision_score(Y_test,Y_tree_test)

recall_score(Y_test,Y_tree_test)

from sklearn import tree
# Assuming your decision tree model is named 'tree_model'
tree.plot_tree(Tree_model_test,max_depth=4)

"""# SVM"""

from sklearn.svm import SVC

SVM_model = SVC(C=100, kernel='linear')
SVM_model.fit(X_train_scale,Y_train)

Y_SVM = SVM_model.predict(X_test_scale)

confusion_matrix(Y_test,Y_SVM)

accuracy_score(Y_test,Y_SVM)

recall_score(Y_test,Y_SVM)

precision_score(Y_test,Y_SVM)